{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Jet-Tagging with PyTorch\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dijet data\n",
    "features = np.load('data/dijet_features_normalized.npy').T\n",
    "labels = np.load('data/dijet_labels.npy')\n",
    "\n",
    "# shuffle the data\n",
    "order = np.arange(len(labels))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(order)\n",
    "features = features[order]\n",
    "labels = labels[order]\n",
    "\n",
    "n_features = features.shape[1]\n",
    "print(n_features)\n",
    "print(f'{features.shape=}, {labels.shape=}')\n",
    "\n",
    "# TODO: create train, val and test splits\n",
    "\n",
    "# TODO: create the datsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate an MLP as specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create the optimizer\n",
    "\n",
    "# TODO: create the criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: create the data loaders, use a batch size of 16\n",
    "\n",
    "# TODO: Implement the training loop, validating after every epoch and keeping track of losses and accuracies\n",
    "\n",
    "for epoch in range(30):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        #TODO: train step\n",
    "            \n",
    "    # TODO: validate\n",
    "            \n",
    "# TODO: Plot the losses and accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the best model and evaluate it on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: experiment with some hyperparameters and discuss your results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: CNNs for Galaxy Classification\n",
    "\n",
    "Read through and run the cells below to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data \n",
    "# it's ~200MB, might take some time depending on your internet speed\n",
    "\n",
    "import urllib.request\n",
    "_, msg = urllib.request.urlretrieve(\n",
    "    \"http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\", \n",
    "    \"data/Galaxy10.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "label_names = [\n",
    "    'Disk, Face-on, No Spiral',\n",
    "    'Smooth, Completely round',\n",
    "    'Smooth, in-between round',\n",
    "    'Smooth, Cigar shaped',\n",
    "    'Disk, Edge-on, Rounded Bulge',\n",
    "    'Disk, Edge-on, Boxy Bulge',\n",
    "    'Disk, Edge-on, No Bulge',\n",
    "    'Disk, Face-on, Tight Spiral',\n",
    "    'Disk, Face-on, Medium Spiral',\n",
    "    'Disk, Face-on, Loose Spiral'\n",
    "]\n",
    "n_classes = len(label_names)\n",
    "\n",
    "# To get the images and labels from file\n",
    "with h5py.File('data/Galaxy10.h5', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "with h5py.File('data/Galaxy10_compressed.h5', 'w') as f:\n",
    "    f.create_dataset('images', data=images.astype(np.float16), compression='gzip')\n",
    "    f.create_dataset('ans', data=labels.astype(np.int32), compression='gzip')\n",
    "    \n",
    "images = images.astype(np.float32)\n",
    "\n",
    "# comply to (batch, channel, height, width) convention of pytorch\n",
    "images = np.moveaxis(images, -1, 1)  \n",
    "# convert to torch\n",
    "images = torch.from_numpy(images)\n",
    "labels = torch.from_numpy(labels)\n",
    "\n",
    "print(f'{images.shape=}, {labels.shape=}')\n",
    "\n",
    "print(labels.shape, images.shape)\n",
    "print(f'\\nNumber of samples per class:')\n",
    "for label, count in zip(*np.unique(labels, return_counts=True)):\n",
    "    print(f'{label_names[label]:40s}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot some samples of each class\n",
    "itemindex = torch.where(labels == 3)\n",
    "itemindex[:3]\n",
    "\n",
    "samples_per_class = 3\n",
    "fig, axss = plt.subplots(samples_per_class, n_classes, figsize=(n_classes * 2, samples_per_class * 2))\n",
    "for label, (label_name, axs) in enumerate(zip(label_names, axss.T)):\n",
    "    idx = torch.where(labels==label)[0][:samples_per_class] # take samples_per_class first occurences\n",
    "    for i, (ind, ax) in enumerate(zip(idx, axs)):\n",
    "        ax.imshow(images[ind].long().moveaxis(0, -1))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == 0:\n",
    "            ax.set_title(label_name.replace(',',',\\n'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize\n",
    "\n",
    "# Compute the mean and standard deviation per channel over the dataset\n",
    "# stds = images.moveaxis(1, 0).reshape(3, -1).std(axis=1)\n",
    "# means = images.moveaxis(1, 0).reshape(3, -1).mean(axis=1)\n",
    "\n",
    "# Use precomputed means and stds\n",
    "stds, means = torch.tensor([37.5412, 31.3756, 26.3283]), torch.tensor([27.7014, 23.8241, 18.1425])\n",
    "\n",
    "# TODO: Normalize the images\n",
    "normalize = Normalize(means, stds)\n",
    "images_normalized = normalize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "n_samples = len(labels)\n",
    "\n",
    "# split the data in training and validation sets, stratifying by the labels\n",
    "train_idx, val_idx = train_test_split(np.arange(n_samples), test_size=0.1, stratify=labels)\n",
    "\n",
    "# create pytorch datasets for training and validation\n",
    "train_dataset = TensorDataset(images_normalized[train_idx].float(), labels[train_idx].long())\n",
    "val_dataset = TensorDataset(images_normalized[val_idx].float(), labels[val_idx].long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#TODO: implement a small CNN as specified on the sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: create DataLoaders for train and val, use a batch size of 16\n",
    "\n",
    "# TODO: instantiate the model, optimizer and criterion\n",
    "\n",
    "# TODO: implement the training loop, validating after every epoch, and make the requested plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: redo (c) with a ResNet\n",
    "# Hint: Training is probably quicker on google colab (https://colab.research.google.com/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlph2]",
   "language": "python",
   "name": "conda-env-mlph2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
